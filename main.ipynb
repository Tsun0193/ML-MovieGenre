{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DistilBertForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.preprocessing import image\n",
    "from torchmetrics.classification import MultilabelF1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml1m/content/dataset/genres.txt', 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genres = [genre.strip() for genre in genre_all]\n",
    "\n",
    "mapping = {}\n",
    "for genre, i in enumerate(genres):\n",
    "    mapping[genre] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('ml1m/content/dataset/users.dat', sep='::',\n",
    "                        engine='python',\n",
    "                        names=['userid', 'gender', 'age', 'occupation', 'zip']).set_index('userid')\n",
    "ratings = pd.read_csv('ml1m/content/dataset/ratings.dat', engine='python',\n",
    "                          sep='::', names=['userid', 'movieid', 'rating', 'timestamp'])\n",
    "movies_train = pd.read_csv('ml1m/content/dataset/movies_train.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre'], encoding='ISO-8859-1', index_col=False).set_index('movieid')\n",
    "movies_test = pd.read_csv('ml1m/content/dataset/movies_test.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre'], encoding='ISO-8859-1', index_col=False).set_index('movieid')\n",
    "movies_train['genre'] = movies_train.genre.str.split('|')\n",
    "movies_train.index.name = 'ID'\n",
    "movies_test['genre'] = movies_test.genre.str.split('|')\n",
    "movies_test.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "Must add overview column to this table via generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, path='ml1m/content/dataset/ml1m-images', genres=genres) -> pd.DataFrame:\n",
    "    df['img_path'] = df.apply(lambda x: os.path.join(path, str(x.name) + '.jpg'), axis=1)\n",
    "    df['label'] = df.genre.apply(lambda x: [1 if genre in x else 0 for genre in genres])\n",
    "    df.drop(columns=['genre'], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = preprocess(movies_train)\n",
    "testset = preprocess(movies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('trainset.csv')\n",
    "testset = pd.read_csv('testset.csv')\n",
    "trainset.label = trainset.label.apply(lambda x: eval(x))\n",
    "testset.label = testset.label.apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3106 777\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gen = AutoTokenizer.from_pretrained(\"MBZUAI/LaMini-Flan-T5-248M\")\n",
    "model_gen = AutoModelForSeq2SeqLM.from_pretrained(\"MBZUAI/LaMini-Flan-T5-248M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(df: pd.DataFrame, model: AutoModelForSeq2SeqLM, tokenizer: AutoTokenizer, device) -> pd.DataFrame:\n",
    "    quote = 'What is the story of the movie {}?'\n",
    "    model_gen.to(device)\n",
    "    model_gen.eval()\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer(quote.format(df.title[i]), return_tensors='pt').input_ids.to(device)\n",
    "            output = model.generate(input_ids, max_length=256, do_sample=True, temperature=0.09)\n",
    "            df.loc[i, 'plot'] = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = generate_plot(trainset, model_gen, tokenizer_gen, device)\n",
    "# testset = generate_plot(testset, model_gen, tokenizer_gen, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1 = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model1 = DistilBertForSequenceClassification .from_pretrained(\"distilbert-base-uncased\", problem_type=\"multi_label_classification\", num_labels=18)\n",
    "model1.config.id2label = mapping\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"dduy193/plot-classification\")\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(\"dduy193/plot-classification\")\n",
    "model2.config.id2label = mapping\n",
    "\n",
    "model3 = models.resnet101(pretrained=False)\n",
    "model3.fc = torch.nn.Linear(2048, len(genres))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Fusion Multimodal Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multimodal(torch.nn.Module):\n",
    "    def __init__(self, model1, model2, model3):\n",
    "        super().__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.fc1 = torch.nn.Linear(18, 18)\n",
    "        self.fc2 = torch.nn.Linear(18, 18)\n",
    "        self.fc3 = torch.nn.Linear(18, 18)\n",
    "\n",
    "    def forward(self, \n",
    "                title_input_ids, title_attention_mask,\n",
    "                plot_input_ids, plot_attention_mask,\n",
    "                image_input):\n",
    "        title_output = self.model1(title_input_ids, title_attention_mask)\n",
    "        plot_output = self.model2(plot_input_ids, plot_attention_mask)\n",
    "        image_output = self.model3(image_input)\n",
    "\n",
    "        title_output = self.fc1(title_output.logits)\n",
    "        plot_output = self.fc2(plot_output.logits)\n",
    "        image_output = self.fc3(image_output)\n",
    "        \n",
    "        output = torch.add(title_output, plot_output)\n",
    "        output = torch.add(output, image_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Datasets & Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Custom Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poroset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, \n",
    "                 tokenizer1, tokenizer2, \n",
    "                 max_len1=64, max_len2=256,\n",
    "                 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "        self.df = df\n",
    "        self.tokenizer1 = tokenizer1\n",
    "        self.tokenizer2 = tokenizer2\n",
    "        self.max_len1 = max_len1\n",
    "        self.max_len2 = max_len2\n",
    "        self.image = image\n",
    "        self.device = device\n",
    "        self.transform = v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        title = row['title']\n",
    "        # Truncate title if it is too long\n",
    "        if len(title) > self.max_len1:\n",
    "            title = title[:self.max_len1]\n",
    "\n",
    "        plot = row['plot']\n",
    "        # Truncate plot if it is too long\n",
    "        if len(plot) > self.max_len2:\n",
    "            plot = plot[:self.max_len2]\n",
    "\n",
    "        label = row['label']\n",
    "        title_encoding = self.tokenizer1(title, truncation=True, padding='max_length', max_length=self.max_len1, return_tensors='pt')\n",
    "        plot_encoding = self.tokenizer2(plot, truncation=True, padding='max_length', max_length=self.max_len2, return_tensors='pt')\n",
    "        \n",
    "        path='ml1m/content/dataset/ml1m-images'\n",
    "        image_path = os.path.join(path, str(row.name) + '.jpg')\n",
    "        if os.path.exists(image_path):\n",
    "            image_input = image.load_img(image_path)\n",
    "            image_input = self.transform(image_input)\n",
    "        else:\n",
    "            image_input = torch.zeros((3, 224, 224))\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'plot': plot,\n",
    "            'title_input_ids': title_encoding['input_ids'].squeeze(),\n",
    "            'title_attention_mask': title_encoding['attention_mask'].squeeze(),\n",
    "            'plot_input_ids': plot_encoding['input_ids'].squeeze(),\n",
    "            'plot_attention_mask': plot_encoding['attention_mask'].squeeze(),\n",
    "            'image_input': image_input,\n",
    "            'label': torch.FloatTensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Poroset(df=trainset, tokenizer1=tokenizer1, tokenizer2=tokenizer2,\n",
    "                   max_len1=64, max_len2=256,\n",
    "                   device=device)\n",
    "testset = Poroset(df=testset, tokenizer1=tokenizer1, tokenizer2=tokenizer2,\n",
    "                  max_len1=64, max_len2=256,\n",
    "                  device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Custom Data Loader\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the data loader is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Poltergeist (1982)\n",
      "Plot:  Poltergeist is a movie about a group of scientists who discover a new species of worm that has been causing a massive outbreak of a disease in the Arctic. The scientists are tasked with identifying the worm and determining its origins. The movie explores t\n",
      "Label:  tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Image:  torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(trainloader))\n",
    "\n",
    "# First sample of the batch\n",
    "print('Title: ', sample['title'][0])\n",
    "print('Plot: ', sample['plot'][0])\n",
    "print('Label: ', sample['label'][0])\n",
    "print('Image: ', sample['image_input'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### GPU & Model Configuration\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multimodal(model1, model2, model3)\n",
    "model.to(device)\n",
    "\n",
    "# Freeze layers\n",
    "for param in model.model2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.model3.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Setting up loss function & optimizer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k = 18):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if len(actual) == 0:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k = 18):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Trainer & Validation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = []\n",
    "history_f1 = []\n",
    "history_mapk = []\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    f1 = MultilabelF1Score(num_labels=18, threshold=0.5, average='macro')\n",
    "    f1.to(device)\n",
    "\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    for _, data in tqdm(enumerate(trainloader, 0), total=len(trainloader)):\n",
    "        title_input_ids = data['title_input_ids'].to(device)\n",
    "        title_attention_mask = data['title_attention_mask'].to(device)\n",
    "        plot_input_ids = data['plot_input_ids'].to(device)\n",
    "        plot_attention_mask = data['plot_attention_mask'].to(device)\n",
    "        image_input = data['image_input'].to(device)\n",
    "        label = data['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            title_input_ids, title_attention_mask,\n",
    "            plot_input_ids, plot_attention_mask,\n",
    "            image_input\n",
    "        )\n",
    "        \n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        f1.update(outputs.sigmoid(), label)\n",
    "        actual.append(label.cpu().numpy())\n",
    "        predicted.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    print(f'Epoch: {epoch}, Train Loss: {loss.item()}, Train F1: {f1.compute().item()}, Train MAP@18: {mapk(actual, predicted)}')\n",
    "    history_loss.append(loss.item())\n",
    "    history_f1.append(f1.compute().item())\n",
    "    history_mapk.append(mapk(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [01:15<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.9618352055549622, Train F1: 0.0798313319683075, Train MAP@18: 0.0011959281066924125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:41<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.054370403289795, Train F1: 0.05500367283821106, Train MAP@18: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'multimodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize\n",
    "plt.plot(history_loss)\n",
    "plt.plot(history_f1)\n",
    "plt.plot(history_mapk)\n",
    "plt.legend(['loss', 'f1', 'mapk'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "def test(testing_loader):\n",
    "    model.eval()\n",
    "    f1 = MultilabelF1Score(num_labels=18, threshold=0.5, average='macro')\n",
    "    f1.to(device)\n",
    "    \n",
    "    actual = []\n",
    "    predicted = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0), total=len(testing_loader)):\n",
    "            title_input_ids = data['title_input_ids'].to(device)\n",
    "            title_attention_mask = data['title_attention_mask'].to(device)\n",
    "            plot_input_ids = data['plot_input_ids'].to(device)\n",
    "            plot_attention_mask = data['plot_attention_mask'].to(device)\n",
    "            image_input = data['image_input'].to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                title_input_ids, title_attention_mask,\n",
    "                plot_input_ids, plot_attention_mask,\n",
    "                image_input\n",
    "            )\n",
    "            actual.append(label.cpu().numpy())\n",
    "            predicted.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            f1.update(outputs.sigmoid(), label)\n",
    "    print(f'Test F1: {f1.compute().item()}, Test MAP@18: {mapk(actual, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencing title and overview\n",
    "def inference(title, overview = None, genres = genres):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        title_encoding = tokenizer(title, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "        title_input_ids = title_encoding['input_ids'].to(device)\n",
    "        title_attention_mask = title_encoding['attention_mask'].to(device)\n",
    "        if overview is not None:\n",
    "            overview_encoding = tokenizer(overview, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "            overview_input_ids = overview_encoding['input_ids'].to(device)\n",
    "            overview_attention_mask = overview_encoding['attention_mask'].to(device)\n",
    "            outputs = model(title_input_ids, title_attention_mask, overview_input_ids, overview_attention_mask)\n",
    "        else:\n",
    "            outputs = model(title_input_ids, title_attention_mask, None, None)\n",
    "        outputs = outputs.cpu().detach().numpy().tolist()\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        print([genres[i] for i in range(len(genres)) if outputs[0][i] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testset[3]['title'])\n",
    "#print genres of the movie in testset in word\n",
    "for i in range(len(genres)):\n",
    "    if testset[3]['label'][i] == 1:\n",
    "        print(genres[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(testset[3]['title'],testset[3]['overview'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
