{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DistilBertForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.preprocessing import image\n",
    "from torchmetrics.classification import MultilabelF1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml1m/content/dataset/genres.txt', 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genres = [genre.strip() for genre in genre_all]\n",
    "\n",
    "mapping = {}\n",
    "for genre, i in enumerate(genres):\n",
    "    mapping[genre] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('ml1m/content/dataset/users.dat', sep='::',\n",
    "                        engine='python',\n",
    "                        names=['userid', 'gender', 'age', 'occupation', 'zip']).set_index('userid')\n",
    "ratings = pd.read_csv('ml1m/content/dataset/ratings.dat', engine='python',\n",
    "                          sep='::', names=['userid', 'movieid', 'rating', 'timestamp'])\n",
    "movies_train = pd.read_csv('ml1m/content/dataset/movies_train.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre'], encoding='ISO-8859-1', index_col=False).set_index('movieid')\n",
    "movies_test = pd.read_csv('ml1m/content/dataset/movies_test.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre'], encoding='ISO-8859-1', index_col=False).set_index('movieid')\n",
    "movies_train['genre'] = movies_train.genre.str.split('|')\n",
    "movies_train.index.name = 'ID'\n",
    "movies_test['genre'] = movies_test.genre.str.split('|')\n",
    "movies_test.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "Must add overview column to this table via generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, path='ml1m/content/dataset/ml1m-images', genres=genres) -> pd.DataFrame:\n",
    "    df['img_path'] = df.apply(lambda x: os.path.join(path, str(x.name) + '.jpg'), axis=1)\n",
    "    df['label'] = df.genre.apply(lambda x: [1 if genre in x else 0 for genre in genres])\n",
    "    df.drop(columns=['genre'], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = preprocess(movies_train)\n",
    "testset = preprocess(movies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('trainset.csv')\n",
    "testset = pd.read_csv('testset.csv')\n",
    "trainset.label = trainset.label.apply(lambda x: eval(x))\n",
    "testset.label = testset.label.apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3106 777\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gen = AutoTokenizer.from_pretrained(\"MBZUAI/LaMini-Flan-T5-248M\")\n",
    "model_gen = AutoModelForSeq2SeqLM.from_pretrained(\"MBZUAI/LaMini-Flan-T5-248M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(df: pd.DataFrame, model: AutoModelForSeq2SeqLM, tokenizer: AutoTokenizer, device) -> pd.DataFrame:\n",
    "    quote = 'What is the story of the movie {}?'\n",
    "    model_gen.to(device)\n",
    "    model_gen.eval()\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer(quote.format(df.title[i]), return_tensors='pt').input_ids.to(device)\n",
    "            output = model.generate(input_ids, max_length=256, do_sample=True, temperature=0.09)\n",
    "            df.loc[i, 'plot'] = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = generate_plot(trainset, model_gen, tokenizer_gen, device)\n",
    "# testset = generate_plot(testset, model_gen, tokenizer_gen, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1 = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model1 = DistilBertForSequenceClassification .from_pretrained(\"distilbert-base-uncased\", problem_type=\"multi_label_classification\", num_labels=18)\n",
    "model1.config.id2label = mapping\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"dduy193/plot-classification\")\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(\"dduy193/plot-classification\")\n",
    "model2.config.id2label = mapping\n",
    "\n",
    "model3 = models.resnet101(pretrained=False)\n",
    "model3.fc = torch.nn.Linear(2048, len(genres))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Fusion Multimodal Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multimodal(torch.nn.Module):\n",
    "    def __init__(self, model1, model2, model3):\n",
    "        super().__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.fc1 = torch.nn.Linear(18, 18)\n",
    "        self.fc2 = torch.nn.Linear(18, 18)\n",
    "        self.fc3 = torch.nn.Linear(18, 18)\n",
    "\n",
    "    def forward(self, \n",
    "                title_input_ids, title_attention_mask,\n",
    "                plot_input_ids, plot_attention_mask,\n",
    "                image_input):\n",
    "        title_output = self.model1(title_input_ids, title_attention_mask)\n",
    "        plot_output = self.model2(plot_input_ids, plot_attention_mask)\n",
    "        image_output = self.model3(image_input)\n",
    "\n",
    "        title_output = self.fc1(title_output.logits)\n",
    "        plot_output = self.fc2(plot_output.logits)\n",
    "        image_output = self.fc3(image_output)\n",
    "        \n",
    "        output = torch.add(title_output, plot_output)\n",
    "        output = torch.add(output, image_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Datasets & Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Custom Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poroset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, \n",
    "                 tokenizer1, tokenizer2, \n",
    "                 max_len1=64, max_len2=256,\n",
    "                 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "        self.df = df\n",
    "        self.tokenizer1 = tokenizer1\n",
    "        self.tokenizer2 = tokenizer2\n",
    "        self.max_len1 = max_len1\n",
    "        self.max_len2 = max_len2\n",
    "        self.image = image\n",
    "        self.device = device\n",
    "        self.transform = v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        title = row['title']\n",
    "        # Truncate title if it is too long\n",
    "        if len(title) > self.max_len1:\n",
    "            title = title[:self.max_len1]\n",
    "\n",
    "        plot = row['plot']\n",
    "        # Truncate plot if it is too long\n",
    "        if len(plot) > self.max_len2:\n",
    "            plot = plot[:self.max_len2]\n",
    "\n",
    "        label = row['label']\n",
    "        title_encoding = self.tokenizer1(title, truncation=True, padding='max_length', max_length=self.max_len1, return_tensors='pt')\n",
    "        plot_encoding = self.tokenizer2(plot, truncation=True, padding='max_length', max_length=self.max_len2, return_tensors='pt')\n",
    "        \n",
    "        path='ml1m/content/dataset/ml1m-images'\n",
    "        image_path = os.path.join(path, str(row.name) + '.jpg')\n",
    "        if os.path.exists(image_path):\n",
    "            image_input = image.load_img(image_path)\n",
    "            image_input = self.transform(image_input)\n",
    "        else:\n",
    "            image_input = torch.zeros((3, 224, 224))\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'plot': plot,\n",
    "            'title_input_ids': title_encoding['input_ids'].squeeze(),\n",
    "            'title_attention_mask': title_encoding['attention_mask'].squeeze(),\n",
    "            'plot_input_ids': plot_encoding['input_ids'].squeeze(),\n",
    "            'plot_attention_mask': plot_encoding['attention_mask'].squeeze(),\n",
    "            'image_input': image_input,\n",
    "            'label': torch.FloatTensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Poroset(df=trainset, tokenizer1=tokenizer1, tokenizer2=tokenizer2,\n",
    "                   max_len1=64, max_len2=256,\n",
    "                   device=device)\n",
    "testset = Poroset(df=testset, tokenizer1=tokenizer1, tokenizer2=tokenizer2,\n",
    "                  max_len1=64, max_len2=256,\n",
    "                  device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Custom Data Loader\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the data loader is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Mr. Magoo (1997)\n",
      "Plot:  Mr. Magoo is a 1997 animated film about a man named Mr. Magoo who is a sailor and a sailor who is stranded on a deserted island. He is rescued by a group of sailors who are trying to find him and rescue him.\n",
      "Label:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Image:  torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(trainloader))\n",
    "\n",
    "# First sample of the batch\n",
    "print('Title: ', sample['title'][0])\n",
    "print('Plot: ', sample['plot'][0])\n",
    "print('Label: ', sample['label'][0])\n",
    "print('Image: ', sample['image_input'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### GPU & Model Configuration\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multimodal(\n",
       "  (model1): DistilBertForSequenceClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (model2): DistilBertForSequenceClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (model3): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=18, out_features=18, bias=True)\n",
       "  (fc2): Linear(in_features=18, out_features=18, bias=True)\n",
       "  (fc3): Linear(in_features=18, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Multimodal(model1, model2, model3)\n",
    "model.to(device)\n",
    "\n",
    "# Freeze layers\n",
    "# for param in model.model2.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Setting up loss function & optimizer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k = 18):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if len(actual) == 0:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k = 18):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Trainer & Validation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = []\n",
    "history_f1 = []\n",
    "history_mapk = []\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    f1 = MultilabelF1Score(num_labels=18, threshold=0.5, average='macro')\n",
    "    f1.to(device)\n",
    "\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    for _, data in tqdm(enumerate(trainloader, 0), total=len(trainloader)):\n",
    "        title_input_ids = data['title_input_ids'].to(device)\n",
    "        title_attention_mask = data['title_attention_mask'].to(device)\n",
    "        plot_input_ids = data['plot_input_ids'].to(device)\n",
    "        plot_attention_mask = data['plot_attention_mask'].to(device)\n",
    "        image_input = data['image_input'].to(device)\n",
    "        label = data['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            title_input_ids, title_attention_mask,\n",
    "            plot_input_ids, plot_attention_mask,\n",
    "            image_input\n",
    "        )\n",
    "        \n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "        actual.extend(label.cpu().numpy())\n",
    "        f1(torch.sigmoid(outputs), label)\n",
    "    print(f'Epoch: {epoch}, Train Loss: {loss.item()}, Train F1: {f1.compute().item()}, Train MAP@18: {mapk(actual, predicted)}')\n",
    "    history_loss.append(loss.item())\n",
    "    history_f1.append(f1.compute().item())\n",
    "    history_mapk.append(mapk(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'multimodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training loss\n",
    "plt.plot(history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "def test(testing_loader):\n",
    "    model.eval()\n",
    "    f1 = MultilabelF1Score(num_labels=18, threshold=0.5, average='macro')\n",
    "    f1.to(device)\n",
    "    \n",
    "    actual = []\n",
    "    predicted = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0), total=len(testing_loader)):\n",
    "            title_input_ids = data['title_input_ids'].to(device)\n",
    "            title_attention_mask = data['title_attention_mask'].to(device)\n",
    "            plot_input_ids = data['plot_input_ids'].to(device)\n",
    "            plot_attention_mask = data['plot_attention_mask'].to(device)\n",
    "            image_input = data['image_input'].to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                title_input_ids, title_attention_mask,\n",
    "                plot_input_ids, plot_attention_mask,\n",
    "                image_input\n",
    "            )\n",
    "            predicted.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            actual.extend(label.cpu().numpy())\n",
    "            f1(torch.sigmoid(outputs), label)\n",
    "    print(f'F1 Score: {f1.compute()}')\n",
    "    print(f'MAP@18: {mapk(actual, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25/25 [00:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.08918388187885284\n",
      "MAP@18: 0.09152009152009154\n"
     ]
    }
   ],
   "source": [
    "test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencing title and overview\n",
    "def inference(title, overview = None, genres = genres):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        title_encoding = tokenizer(title, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "        title_input_ids = title_encoding['input_ids'].to(device)\n",
    "        title_attention_mask = title_encoding['attention_mask'].to(device)\n",
    "        if overview is not None:\n",
    "            overview_encoding = tokenizer(overview, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "            overview_input_ids = overview_encoding['input_ids'].to(device)\n",
    "            overview_attention_mask = overview_encoding['attention_mask'].to(device)\n",
    "            outputs = model(title_input_ids, title_attention_mask, overview_input_ids, overview_attention_mask)\n",
    "        else:\n",
    "            outputs = model(title_input_ids, title_attention_mask, None, None)\n",
    "        outputs = outputs.cpu().detach().numpy().tolist()\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        print([genres[i] for i in range(len(genres)) if outputs[0][i] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testset[3]['title'])\n",
    "#print genres of the movie in testset in word\n",
    "for i in range(len(genres)):\n",
    "    if testset[3]['label'][i] == 1:\n",
    "        print(genres[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(testset[3]['title'],testset[3]['overview'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
